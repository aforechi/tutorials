{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import data\n",
    "Adapted from: http://rnduja.github.io/2015/10/13/torch-mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use data from the standard MNIST set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'cunn'\n",
    "require 'cudnn'\n",
    "require 'optim'\n",
    "mnist = require 'mnist'\n",
    "\n",
    "backend = cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullset = mnist.traindataset()\n",
    "testset = mnist.testdataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  data : ByteTensor - size: 60000x28x28\n",
       "  size : 60000\n",
       "  label : ByteTensor - size: 60000\n",
       "}\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We inspect the data just to get an idea of the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVQokWNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16AiykZfAAAAABJRU5ErkJggg==",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 28,
       "width": 28
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "itorch.image(fullset.data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullset.label[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can split the full dataset into a trainin component and a validation component, which will be used to train hyperparameters.\n",
    "\n",
    "While doing so, we convert the dataset to double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = {\n",
    "    size = 50000,\n",
    "    data = fullset.data[{{1,50000}}]:double(),\n",
    "    label = fullset.label[{{1,50000}}]\n",
    "}\n",
    "trainset.data = trainset.data:cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "validationset = {\n",
    "    size = 10000,\n",
    "    data = fullset.data[{{50001,60000}}]:double(),\n",
    "    label = fullset.label[{{50001,60000}}]\n",
    "}\n",
    "validationset.data = validationset.data:cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a model with a single hidden layer, using a hyperbolic tangent activation, and a softmax output. We also use a first layer to reshape the input - which is a 28x28 square - to fit into the linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "model:add(nn.Reshape(28*28))\n",
    "model:add(nn.Linear(28*28, 30))\n",
    "model:add(nn.Tanh())\n",
    "model:add(nn.Linear(30, 10))\n",
    "model:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "--This is a LeNet model. For more information: http://yann.lecun.com/exdb/lenet/\n",
    "\n",
    "model = nn.Sequential()\n",
    "model:add(nn.MulConstant(0.0125)) -- 1/(standard deviation on MNIST dataset)\n",
    "model:add(backend.SpatialConvolution(1,20,5,5,1,1,0)) -- channels*28*28 -> 20*24*24\n",
    "model:add(backend.SpatialMaxPooling(2, 2, 2, 2)) -- 20*24*24 -> 20*12*12\n",
    "model:add(backend.SpatialConvolution(20,50,5,5,1,1,0)) -- 20*12*12 -> 50*8*8\n",
    "model:add(backend.SpatialMaxPooling(2,2,2,2)) --  50*8*8 -> 50*4*4\n",
    "model:add(nn.View(-1):setNumInputDims(3))  -- 50*4*4 -> 800\n",
    "model:add(nn.Linear(800,500))  -- 800 -> 500\n",
    "model:add(backend.ReLU())\n",
    "model:add(nn.Linear(500, 10))  -- 500 -> nclasses\n",
    "model:add(nn.LogSoftMax())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = model:cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a loss function, using the negative log likelihood criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion()\n",
    "criterion = criterion:cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained in [the documentation](https://github.com/torch/nn/blob/master/doc/criterion.md), the NLL criterion require the output of the neural network to contain log-probabilities of each class, and this is the reason for our use of `LogSoftMax` above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the descent algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make use of the `optim` package to train the network. `optim` contains several optimization algorithms. All of these algorithms assume the same parameters:\n",
    "\n",
    "- a closure that computes the loss, and its gradient wrt to `x`, given a point `x`\n",
    "- a point x\n",
    "- some parameters, which are algorithm-specific\n",
    "\n",
    "We define a `step` function that performs training for a single epoch and returns the current loss value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_params = {\n",
    "   learningRate = 1e-2,\n",
    "   learningRateDecay = 1e-4,\n",
    "   weightDecay = 1e-3,\n",
    "   momentum = 1e-4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, dl_dx = model:getParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = function(batch_size)\n",
    "    local current_loss = 0\n",
    "    local count = 0\n",
    "    local shuffle = torch.randperm(trainset.size)\n",
    "    batch_size = batch_size or 32\n",
    "    \n",
    "    for t = 1,trainset.size,batch_size do\n",
    "        -- setup inputs and targets for this mini-batch\n",
    "        local size = math.min(t + batch_size - 1, trainset.size) - t\n",
    "        local inputs = torch.CudaTensor(size, 1, 28, 28)\n",
    "        local targets = torch.CudaTensor(size)\n",
    "  \n",
    "        for i = 1,size do\n",
    "            local input = trainset.data[shuffle[i+t]]\n",
    "            local target = trainset.label[shuffle[i+t]]\n",
    "            -- if target == 0 then target = 10 end\n",
    "            inputs[i] = input\n",
    "            targets[i] = target\n",
    "        end\n",
    "        targets:add(1)\n",
    "        \n",
    "        local feval = function(x_new)\n",
    "            -- reset data\n",
    "            if x ~= x_new then x:copy(x_new) end\n",
    "            dl_dx:zero()\n",
    "\n",
    "            -- perform mini-batch gradient descent\n",
    "            local loss = criterion:forward(model:forward(inputs), targets)\n",
    "            model:backward(inputs, criterion:backward(model.output, targets))\n",
    "\n",
    "            return loss, dl_dx\n",
    "        end\n",
    "        \n",
    "        _, fs = optim.sgd(feval, x, sgd_params)\n",
    "        -- fs is a table containing value of the loss function\n",
    "        -- (just 1 value for the SGD optimization)\n",
    "        count = count + 1\n",
    "        current_loss = current_loss + fs[1]\n",
    "    end\n",
    "\n",
    "    -- normalize loss\n",
    "    return current_loss / count\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the training, we also need to be able to evaluate accuracy on a separate dataset, in order to define when to stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = function(dataset, batch_size)\n",
    "    local count = 0\n",
    "    batch_size = batch_size or 32\n",
    "    \n",
    "    for i = 1,dataset.size,batch_size do\n",
    "        local size = math.min(i + batch_size - 1, dataset.size) - i\n",
    "        local inputs = dataset.data[{{i,i+size-1}}]:reshape(size,1,28,28):cuda()\n",
    "        local targets = dataset.label[{{i,i+size-1}}]:cudaLong()\n",
    "        local outputs = model:forward(inputs)\n",
    "        local _, indices = torch.max(outputs, 2)\n",
    "        indices:add(-1)\n",
    "        local guessed_right = indices:eq(targets):sum()\n",
    "        count = count + guessed_right\n",
    "    end\n",
    "\n",
    "    return count / dataset.size\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to perform the actual training. After each epoch, we evaluate the accuracy on the validation dataset, in order to decide whether to stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch: 1 Current loss: 0.349721\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy on the validation set: 0.936300\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 2 Current loss: 0.107826\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy on the validation set: 0.937300\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 3 Current loss: 0.076105\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy on the validation set: 0.941600\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 4 Current loss: 0.060696\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy on the validation set: 0.948600\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 5 Current loss: 0.051656\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy on the validation set: 0.951000\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 6 Current loss: 0.044242\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy on the validation set: 0.952700\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 7 Current loss: 0.040426\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy on the validation set: 0.952300\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 8 Current loss: 0.037110\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy on the validation set: 0.955200\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 9 Current loss: 0.033439\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy on the validation set: 0.954500\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 10 Current loss: 0.030614\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy on the validation set: 0.953300\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 11 Current loss: 0.028584\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy on the validation set: 0.954900\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch: 12 Current loss: 0.026379\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy on the validation set: 0.954600\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do\n",
    "    local last_accuracy = 0\n",
    "    local decreasing = 0\n",
    "    local threshold = 1 -- how many deacreasing epochs we allow\n",
    "    for i = 1,max_iters do\n",
    "        local loss = step()\n",
    "        print(string.format('Epoch: %d Current loss: %4f', i, loss))\n",
    "        local accuracy = eval(validationset)\n",
    "        print(string.format('Accuracy on the validation set: %4f', accuracy))\n",
    "        if accuracy < last_accuracy then\n",
    "            if decreasing > threshold then break end\n",
    "            decreasing = decreasing + 1\n",
    "        else\n",
    "            decreasing = 0\n",
    "        end\n",
    "        last_accuracy = accuracy\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test the model accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "--testset.data = testset.data:double()\n",
    "testset.data = testset.data:cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9577\t\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Saving and restoring the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `paths` module can be used to manipulate filesystem paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = require 'paths'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = paths.concat(paths.cwd(), 'model.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/home/avelino/torch-tutorials/model.net\t\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then save our model to file like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\t\n",
       "\u001b[1;35mtorch.save(filename, object [, format, referenced])\u001b[0m\n",
       "\n",
       "\n",
       "Writes\u001b[0;32m object \u001b[0minto a file named\u001b[0;32m filename \u001b[0m. The\u001b[0;32m format \u001b[0mcan be set \n",
       "to\u001b[0;32m ascii \u001b[0mor\u001b[0;32m binary \u001b[0m(default is binary). Binary format is platform\n",
       "dependent, but typically more compact and faster to read/write. The ASCII\n",
       "format is platform-independent, and should be used to share data structures\n",
       "across platforms. The option\u001b[0;32m referenced \u001b[0mspecifies if\n",
       "\u001b[0mobject references\u001b[0m should be tracked or not\n",
       "(\u001b[0;32m true \u001b[0mby default).\n",
       "\u001b[0;36m\u001b[0;32m -- arbitrary object:\n",
       "obj = {\n",
       "   mat = torch.randn(10,10),\n",
       "   name = '10',\n",
       "   test = {\n",
       "      entry = 1\n",
       "   }\n",
       "}\n",
       "-- save to disk:\n",
       "torch.save('test.dat', obj) \u001b[0m\u001b[0m\t\n",
       "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\t\n",
       "\n"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "help(torch.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(filename, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check that restoring from file works as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\t\n",
       "\u001b[1;35m[object] torch.load(filename [, format, referenced])\u001b[0m\n",
       "\n",
       "\n",
       "Reads\u001b[0;32m object \u001b[0mfrom a file named\u001b[0;32m filename \u001b[0m.\n",
       "The\u001b[0;32m format \u001b[0mcan be set to\u001b[0;32m ascii \u001b[0m,\u001b[0;32m binary \u001b[0m,\u001b[0;32m b32 \u001b[0mor\u001b[0;32m b64 \u001b[0m(default \n",
       "is binary).\n",
       "Binary format is platform dependent, but typically more compact and faster \n",
       "to read/write.\n",
       "Use\u001b[0;32m b32 \u001b[0m/\u001b[0;32m b64 \u001b[0m, instead of\u001b[0;32m binary \u001b[0m, for loading files saved on a \n",
       "32/64 bit OS.\n",
       "The ASCII format is platform-independent, and may be used to share data \n",
       "structures across platforms.\n",
       "The option\u001b[0;32m referenced \u001b[0mspecifies if \u001b[0mobject references\u001b[0m should be tracked \n",
       "or not (\u001b[0;32m true \u001b[0mby default).\n",
       "Note that files written with\u001b[0;32m referenced \u001b[0mat\u001b[0;32m true \u001b[0mcannot be loaded with\u001b[0;32m \n",
       "referenced \u001b[0mat\u001b[0;32m false \u001b[0m.\n",
       "\u001b[0;36m\u001b[0;32m -- given serialized object from section above, reload:\n",
       "obj = torch.load('test.dat')\n",
       "print(obj)\n",
       "-- will print:\n",
       "-- {[mat]  = DoubleTensor - size: 10x10\n",
       "--  [name] = string : &quot;10&quot;\n",
       "--  [test] = table - size: 0} \u001b[0m\u001b[0m\t\n",
       "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\t\n",
       "\n"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "help(torch.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = torch.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We redefine our evaluation function to use the loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval1 = function(dataset)\n",
    "   local count = 0\n",
    "   for i = 1,dataset.size do\n",
    "      local output = model1:forward(dataset.data[i])\n",
    "      local _, index = torch.max(output, 1) -- max index\n",
    "      local digit = index[1] - 1\n",
    "      if digit == dataset.label[i] then count = count + 1 end\n",
    "   end\n",
    "\n",
    "   return count / dataset.size\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9577\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACoAAAAcCAAAAAAyi3I3AAACu0lEQVQ4jbXQ7U/MAQDA8W+/fp0ezlWH6tJzToeuhjoPacx1ruTpNjXKZdiy2jy8yAt53ppZmxdRXojNVsvQNKEwUuvQLplwKd2lwnq4qER6wPkPlBe+rz+vvk4OpptIgkffqiVp5I4q813bkO4YHos4w033C5MBxVwcMYdbr3M/5ENnwWuRbEnoyw5w9c5PHICcBkXWJAQ0ZFrvQJFGl9cN0t8JxbsR8FRYh26DySLURYLf8b2+E9Cv82xOhCxFjdtBKJaNaVWInJOJijTQfXOofkDLZ/WXvCTuJp2SvMrBpH28PgpCzq5reZQkoPwe1dIIjbfjrRXQUf28Yjb47/ezzQelYvdEL9QNd41uwWn6B4RpS0T0EdKijPOEacN8HlyjTLC/ftiBNrU/3M1ATLKs7Hsra2YomqTPBPT19StugKrJIdWBi7zkhwEODYXpZDAoGc/YCg7PJh0IyDaGzpRDfMTAtVcw0Tj+WAJ2ucvXZjhg0I8Hg22ue1c3AlcC41TJULPQnDoCbR+DZp2DvPz7pYthaXV1eD5w1X9tGgIhCqXpKXyqmUs72M31PXtAuWhswR14W9hl8wFX47Ct8r/NOntd9jSpnJQ5vaaUIi5anGeEZnL40pjvCSOa97ue2N+h9gqM8U0XqTAbj9aCxe2jTzQ0V7r8TIb20T2aALBqyxPUYCh867sMgec75c4ZMLJLI94Ch6j/2QCW7TFv6iFdkrWjCu7N2lQ7iYB/8ODDXJhXGi/fDM9W1uXGwYp3QYIbJOR4tW6AQacXKZM4n1T7/WrN1NDZ0zbgqeer9+qSUSOOeU96K/dxLLxvuCadFtffH7yX/59ZAmVHFhovQ7baPzJrCtqkjhZNEJuocqqdgnqf8VhshtOx27ZH/pWK2OKrBlNBXeARY5+ClqOLHYK4m3FBfX+l/zDrD09qABve2QCiAAAAAElFTkSuQmCC",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 28,
       "width": 42
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "itorch.image(model.modules[2].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
